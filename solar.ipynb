{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46fd2959-009f-431e-97b0-e993f5d31431",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/UpstageAI/cookbook/blob/main/solar.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "\n",
    "# Solar\n",
    "\n",
    "In this notebook, we'll use the Solar APIs provided by Upstage.\n",
    "Solar provides LLM, Embedding, and Layout Analysis apis and is integrated with langchain and llamaindex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f916ed-1bdd-4ef9-930c-c85e6b64f16c",
   "metadata": {},
   "source": [
    "## APIs\n",
    "\n",
    "The APIs that Upstage currently offers.\n",
    "\n",
    "1. Chat\n",
    "2. Translation\n",
    "3. Groundedness Check\n",
    "4. Function Calling\n",
    "5. Embedding\n",
    "6. Document OCR\n",
    "7. Layout Analysis\n",
    "8. Key Information Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec161135-705c-4688-b8ce-73a69cdf3df0",
   "metadata": {},
   "source": [
    "# Setting\n",
    "\n",
    "First, create your upstage api key from [upstage console](https://console.upstage.ai/api-keys). and set UPSTAGE_API_KEY environ variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8fb2e5f-dc26-45d6-9dcc-124399b8c58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q llama_index_llms_upstage==0.1.3 llama_index_embeddings_upstage llama_index\n",
    "!pip install -q langchain langchain_upstage==0.1.6rc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bf50185-417a-4656-92cc-f18509bd6e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "upstage_api_key = os.environ.setdefault(\"UPSTAGE_API_KEY\", \"XXX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59c9c52-75c2-43e4-9204-4eca46683c25",
   "metadata": {},
   "source": [
    "## Chat\n",
    "\n",
    "#### with http request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47091ee4-9dce-4c65-b913-fa9356328b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'f1231aa8-e6f9-4da7-b0bc-9ca633fdffe9', 'object': 'chat.completion', 'created': 1718956256, 'model': 'solar-1-mini-chat-240612', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'Hey there! How can I assist you today?'}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 11, 'total_tokens': 35}, 'system_fingerprint': None}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = 'https://api.upstage.ai/v1/solar/chat/completions'\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {upstage_api_key}',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "data = {\n",
    "    \"model\": \"solar-1-mini-chat\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Hello!\"\n",
    "        }\n",
    "    ],\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.1,\n",
    "    \"stream\": False\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35638172-c627-4098-b7e5-695fc3d66a0c",
   "metadata": {},
   "source": [
    "#### with langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d384183-6d2b-4c45-94a9-d7691da8fa62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Oh, hey there! I'm doing pretty good, thanks for asking. Just enjoying the beautiful day and catching up on some reading. How about you?\" response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 28, 'total_tokens': 61}, 'model_name': 'solar-1-mini-chat', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-56466bac-5026-4309-945a-70ab41aa32e9-0' usage_metadata={'input_tokens': 28, 'output_tokens': 33, 'total_tokens': 61}\n"
     ]
    }
   ],
   "source": [
    "from langchain_upstage import ChatUpstage\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    " \n",
    "chat = ChatUpstage()\n",
    " \n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful assistant.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"Hi, how are you?\"\n",
    "    )\n",
    "]\n",
    "response = chat.invoke(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64464e1e-4d60-4c20-8273-09205e9ee8ab",
   "metadata": {},
   "source": [
    "#### with llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "850f129a-c077-4959-8b0e-3642ca84c430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Hello! I'm doing well, thank you for asking. How about you?\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.upstage import Upstage\n",
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "llm = Upstage()\n",
    "\n",
    "response = llm.chat(messages=[\n",
    "  ChatMessage(role=\"system\", content=\"You are a helpful assistant.\"),\n",
    "  ChatMessage(role=\"user\", content=\"Hi, how are you?\")\n",
    "])\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e881a9af-ae70-4b0d-86e2-538505b79910",
   "metadata": {},
   "source": [
    "# Translation\n",
    "\n",
    "In the translation API, you can set the translation style by first entering a sample translation message.\n",
    "\n",
    "#### with http request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9732b702-b50f-42c5-a752-9502b45cad2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'cd3b4f8b-e91f-41ea-99d7-bac0688587ba', 'object': 'chat.completion', 'created': 1718959553, 'model': 'solar-1-mini-translate-koen-240507', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'Mom went in too'}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 55, 'completion_tokens': 6, 'total_tokens': 61}, 'system_fingerprint': None}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = 'https://api.upstage.ai/v1/solar/chat/completions'\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {upstage_api_key}',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "data = {\n",
    "    \"model\": \"solar-1-mini-translate-koen\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"아버지가방에들어가셨다.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Father went into his room\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"엄마도들어가셨다.\"\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7769a0ce-b136-47bf-9658-71630c08d2f4",
   "metadata": {},
   "source": [
    "#### with langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3049e04b-6d18-41a0-8784-b339bb7581a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Mom went in too' response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 53, 'total_tokens': 59}, 'model_name': 'solar-1-mini-translate-koen', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-eb1a24d4-2aba-4d5c-91ed-5ba81a2e3ed2-0' usage_metadata={'input_tokens': 53, 'output_tokens': 6, 'total_tokens': 59}\n"
     ]
    }
   ],
   "source": [
    "from langchain_upstage import ChatUpstage\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat = ChatUpstage(model=\"solar-1-mini-translate-koen\")\n",
    "\n",
    "messages = [\n",
    "  HumanMessage(content=\"아버지가방에들어가셨다\"),\n",
    "  AIMessage(content=\"Father went into his room\"),\n",
    "  HumanMessage(content=\"엄마도들어가셨다\"),\n",
    "]\n",
    "response = chat.invoke(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc0aaeb-f5c5-4527-8b1c-a0f1a5c4b0d6",
   "metadata": {},
   "source": [
    "#### with llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6478290b-30fd-4c91-8862-0c1c67e954b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Mom went in too\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.upstage import Upstage\n",
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "llm = Upstage(model=\"solar-1-mini-translate-koen\")\n",
    "response = llm.chat(messages=[\n",
    "  ChatMessage(role=\"user\", content=\"아버지가방에들어가셨다\"),\n",
    "  ChatMessage(role=\"assistant\", content=\"Father went into his room\"),\n",
    "  ChatMessage(role=\"user\", content=\"엄마도들어가셨다\"),\n",
    "])\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68d9bec-8be2-418c-9da4-a672a7cacaec",
   "metadata": {},
   "source": [
    "# Groundedness Check\n",
    "\n",
    "Large Language Models (LLMs) are capable of generating elaborate, information-rich texts, but they are prone to hallucinations -- they can produce factually incorrect (i.e., ungrounded) responses. A popular approach to overcoming this limitation of LLMs is to provide chunks of text, often called \"contexts,\" which LLMs can use as a point of reference to generate factually correct outputs. This approach is known as Retrieval-Augmented Generation, or RAG.\n",
    "\n",
    "However, RAG does not always guarantee truthful answers from LLMs. Therefore, an additional step is required to check whether a model-generated output is indeed grounded in a given context. The Groundedness Check API is specifically designed for this purpose: to check the groundedness of an assistant's response to a context provided by a user. Given two messages – a user-provided context and a model response – the API will return whether the response is grounded, not grounded, or if it is unsure about the groundedness of the response to the context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eea1072-ba04-413a-bab9-e6ff6a3d93ac",
   "metadata": {},
   "source": [
    "#### with http request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18fc796b-1672-4dff-8547-9537f5051355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='f0b0169e-08d0-40a5-80b9-98bc316997e1', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='notGrounded', role='assistant', function_call=None, tool_calls=None))], created=1719205302, model='solar-1-mini-groundedness-check-240502', object='chat.completion', system_fingerprint='', usage=CompletionUsage(completion_tokens=5, prompt_tokens=198, total_tokens=203))\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    " \n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"UPSTAGE_API_KEY\"),\n",
    "    base_url=\"https://api.upstage.ai/v1/solar\"\n",
    ")\n",
    " \n",
    "response = client.chat.completions.create(\n",
    "\t\tmodel=\"solar-1-mini-groundedness-check\",\n",
    "\t\tmessages=[\n",
    "\t\t\t\t{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Mauna Kea is an inactive volcano on the island of Hawaiʻi. Its peak is 4,207.3 m above sea level, making it the highest point in Hawaii and second-highest peak of an island on Earth.\"\n",
    "        },\n",
    "\t\t\t\t{\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Mauna Kea is 5,207.3 meters tall.\"\n",
    "        }\n",
    "\t\t]\n",
    ")\n",
    " \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee57ae3-6658-4cb4-bc62-1c0a078a82f3",
   "metadata": {},
   "source": [
    "#### with langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b6237ac-aeee-4e14-88f2-08f6d0edb37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notGrounded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_upstage import UpstageGroundednessCheck\n",
    "\n",
    "groundedness_check = UpstageGroundednessCheck()\n",
    "\n",
    "request_input = {\n",
    "    \"context\": \"Mauna Kea is an inactive volcano on the island of Hawai'i. Its peak is 4,207.3 m above sea level, making it the highest point in Hawaii and second-highest peak of an island on Earth.\",\n",
    "    \"answer\": \"Mauna Kea is 5,207.3 meters tall.\",\n",
    "}\n",
    "response = groundedness_check.invoke(request_input)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebcac2d-7d82-4732-b4fa-faec939237db",
   "metadata": {},
   "source": [
    "#### with llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89f584c1-512d-4dc4-963a-255a79fcdb2d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Could not automatically map solar-1-mini-groundedness-check to a tokeniser. Please use `tiktoken.get_encoding` to explicitly get the tokeniser you expect.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatMessage\n\u001b[1;32m      4\u001b[0m llm \u001b[38;5;241m=\u001b[39m Upstage(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolar-1-mini-groundedness-check\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m  \u001b[49m\u001b[43mChatMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrole\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMauna Kea is an inactive volcano on the island of Hawaiʻi. Its peak is 4,207.3 m above sea level, making it the highest point in Hawaii and second-highest peak of an island on Earth.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m  \u001b[49m\u001b[43mChatMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrole\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43massistant\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMauna Kea is 5,207.3 meters tall.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[0;32m~/upstage/projects/upstage-cookbook/.venv/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py:230\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[1;32m    227\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[1;32m    228\u001b[0m )\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[0;32m~/upstage/projects/upstage-cookbook/.venv/lib/python3.10/site-packages/llama_index/core/llms/callbacks.py:172\u001b[0m, in \u001b[0;36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat\u001b[0;34m(_self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m event_id \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_event_start(\n\u001b[1;32m    164\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[1;32m    165\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m     },\n\u001b[1;32m    170\u001b[0m )\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     f_return_val \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    174\u001b[0m     callback_manager\u001b[38;5;241m.\u001b[39mon_event_end(\n\u001b[1;32m    175\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[1;32m    176\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mEXCEPTION: e},\n\u001b[1;32m    177\u001b[0m         event_id\u001b[38;5;241m=\u001b[39mevent_id,\n\u001b[1;32m    178\u001b[0m     )\n",
      "File \u001b[0;32m~/upstage/projects/upstage-cookbook/.venv/lib/python3.10/site-packages/llama_index/llms/openai/base.py:300\u001b[0m, in \u001b[0;36mOpenAI.chat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     chat_fn \u001b[38;5;241m=\u001b[39m completion_to_chat_decorator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_complete)\n\u001b[0;32m--> 300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mchat_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/upstage/projects/upstage-cookbook/.venv/lib/python3.10/site-packages/llama_index/core/base/llms/generic_utils.py:143\u001b[0m, in \u001b[0;36mcompletion_to_chat_decorator.<locals>.wrapper\u001b[0;34m(messages, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(messages: Sequence[ChatMessage], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResponse:\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# normalize input\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m messages_to_prompt(messages)\n\u001b[0;32m--> 143\u001b[0m     completion_response \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# normalize output\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m completion_response_to_chat_response(completion_response)\n",
      "File \u001b[0;32m~/upstage/projects/upstage-cookbook/.venv/lib/python3.10/site-packages/tenacity/__init__.py:330\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(\n\u001b[1;32m    327\u001b[0m     f, functools\u001b[38;5;241m.\u001b[39mWRAPPER_ASSIGNMENTS \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__defaults__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__kwdefaults__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    328\u001b[0m )\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/upstage/projects/upstage-cookbook/.venv/lib/python3.10/site-packages/tenacity/__init__.py:467\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 467\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/upstage/projects/upstage-cookbook/.venv/lib/python3.10/site-packages/tenacity/__init__.py:368\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    366\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 368\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/upstage/projects/upstage-cookbook/.venv/lib/python3.10/site-packages/tenacity/__init__.py:390\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[0;32m--> 390\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.13_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.13_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/upstage/projects/upstage-cookbook/.venv/lib/python3.10/site-packages/tenacity/__init__.py:470\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 470\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    472\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/upstage/projects/upstage-cookbook/.venv/lib/python3.10/site-packages/llama_index/llms/openai/base.py:499\u001b[0m, in \u001b[0;36mOpenAI._complete\u001b[0;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[1;32m    497\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_client()\n\u001b[1;32m    498\u001b[0m all_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_model_kwargs(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 499\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_max_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreuse_client:\n\u001b[1;32m    502\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    503\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m    504\u001b[0m         stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mall_kwargs,\n\u001b[1;32m    506\u001b[0m     )\n",
      "File \u001b[0;32m~/upstage/projects/upstage-cookbook/.venv/lib/python3.10/site-packages/llama_index/llms/openai/base.py:557\u001b[0m, in \u001b[0;36mOpenAI._update_max_tokens\u001b[0;34m(self, all_kwargs, prompt)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_max_tokens\u001b[39m(\u001b[38;5;28mself\u001b[39m, all_kwargs: Dict[\u001b[38;5;28mstr\u001b[39m, Any], prompt: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    556\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Infer max_tokens for the payload, if possible.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 557\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    558\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;66;03m# NOTE: non-chat completion endpoint requires max_tokens to be set\u001b[39;00m\n",
      "File \u001b[0;32m~/upstage/projects/upstage-cookbook/.venv/lib/python3.10/site-packages/llama_index/llms/openai/base.py:280\u001b[0m, in \u001b[0;36mOpenAI._tokenizer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_tokenizer\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tokenizer]:\n\u001b[1;32m    274\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m    Get a tokenizer for this model, or None if a tokenizing method is unknown.\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    OpenAI can do this using the tiktoken package, subclasses may not have\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;124;03m    this convenience.\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtiktoken\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding_for_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_model_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/upstage/projects/upstage-cookbook/.venv/lib/python3.10/site-packages/tiktoken/model.py:103\u001b[0m, in \u001b[0;36mencoding_for_model\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencoding_for_model\u001b[39m(model_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Encoding:\n\u001b[1;32m     99\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the encoding used by a model.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    Raises a KeyError if the model name is not recognised.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_encoding(\u001b[43mencoding_name_for_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/upstage/projects/upstage-cookbook/.venv/lib/python3.10/site-packages/tiktoken/model.py:90\u001b[0m, in \u001b[0;36mencoding_name_for_model\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m model_encoding_name\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoding_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not automatically map \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to a tokeniser. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `tiktoken.get_encoding` to explicitly get the tokeniser you expect.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m encoding_name\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Could not automatically map solar-1-mini-groundedness-check to a tokeniser. Please use `tiktoken.get_encoding` to explicitly get the tokeniser you expect.'"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.upstage import Upstage\n",
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "llm = Upstage(model=\"solar-1-mini-groundedness-check\")\n",
    "response = llm.chat(messages=[\n",
    "  ChatMessage(role=\"user\", content=\"Mauna Kea is an inactive volcano on the island of Hawaiʻi. Its peak is 4,207.3 m above sea level, making it the highest point in Hawaii and second-highest peak of an island on Earth.\"),\n",
    "  ChatMessage(role=\"assistant\", content=\"Mauna Kea is 5,207.3 meters tall.\"),\n",
    "])\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e965b649-03f0-439d-8c19-0b602f496545",
   "metadata": {},
   "source": [
    "# Function Calling\n",
    "\n",
    "A function calling occurs when you interact with the Chat API to communicate with a Language Learning Model (LLM). Within the tool array, you have the flexibility to define custom functions. This capability enables the model to dynamically generate and provide function signatures in JSON format, facilitating seamless integration with external tools and applications.\n",
    "\n",
    "#### with http request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3e71edf-538b-4f57-869c-bbda397901c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='e106a460-efcc-41c8-87e9-5e825472b92f', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The weather in San Francisco is currently 65°F with partly cloudy skies.\\nThe weather in Seoul is currently 45°C with mostly sunny skies.\\nThe weather in Paris is currently 15°C with mostly cloudy skies.\\nFinal Answer: The weather in San Francisco is currently 65°F with partly cloudy skies, the weather in Seoul is currently 45°C with mostly sunny skies, and the weather in Paris is currently 15°C with mostly cloudy skies.', role='assistant', function_call=None, tool_calls=None))], created=1719455774, model='solar-1-mini-chat-240612', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=120, prompt_tokens=761, total_tokens=881))\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    " \n",
    "client = OpenAI(api_key=os.environ.get(\"UPSTAGE_API_KEY\"), base_url=\"https://api.upstage.ai/v1/solar\")\n",
    " \n",
    " \n",
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    if \"seoul\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Seoul\", \"temperature\": \"10\", \"unit\": unit})\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps(\n",
    "            {\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": unit}\n",
    "        )\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n",
    " \n",
    " \n",
    "def run_conversation():\n",
    "    # Step 1: send the conversation and available functions to the model\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What's the weather like in San Francisco, Seoul, and Paris?\",\n",
    "        }\n",
    "    ]\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_current_weather\",\n",
    "                \"description\": \"Get the current weather in a given location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                        },\n",
    "                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                    },\n",
    "                    \"required\": [\"location\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"solar-1-mini-chat\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    " \n",
    "    # Step 2: check if the model wanted to call a function\n",
    "    if tool_calls:\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        available_functions = {\n",
    "            \"get_current_weather\": get_current_weather,\n",
    "        }  # only one function in this example, but you can have multiple\n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "        # Step 4: send the info for each function call and function response to the model\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            function_response = function_to_call(\n",
    "                location=function_args.get(\"location\"),\n",
    "                unit=function_args.get(\"unit\"),\n",
    "            )\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )  # extend conversation with function response\n",
    "        second_response = client.chat.completions.create(\n",
    "            model=\"solar-1-mini-chat\",\n",
    "            messages=messages,\n",
    "        )  # get a new response from the model where it can see the function response\n",
    "        return second_response\n",
    " \n",
    " \n",
    "print(run_conversation())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedb2519-7a28-4af6-afeb-f015929bcb13",
   "metadata": {},
   "source": [
    "#### with langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99075034-a4c0-4360-8d29-e6fa3eb17e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in San Francisco is 59°F.\n"
     ]
    }
   ],
   "source": [
    "from langchain_upstage import ChatUpstage\n",
    "from langchain.tools import tool\n",
    "import json\n",
    " \n",
    " \n",
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "@tool\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"\n",
    "    return location's weather information\n",
    "    \"\"\"\n",
    "    weather_data = {\n",
    "        \"San Francisco\": {\"celsius\": \"15°C\", \"fahrenheit\": \"59°F\"},\n",
    "        \"Seoul\": {\"celsius\": \"16°C\", \"fahrenheit\": \"61°F\"},\n",
    "        \"Paris\": {\"celsius\": \"11°C\", \"fahrenheit\": \"52°F\"},\n",
    "    }\n",
    "    return f\"The weather in {location} is {weather_data[location][unit]}.\"\n",
    " \n",
    " \n",
    "available_functions = {\"get_current_weather\": get_current_weather}\n",
    " \n",
    "llm = ChatUpstage()\n",
    " \n",
    "tools = [get_current_weather]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    " \n",
    " \n",
    "# Step 1: send the conversation and available functions to the model\n",
    "messages = [{\"role\": \"user\", \"content\": \"How is the weather in San Francisco today?\"}]\n",
    "response = llm_with_tools.invoke(messages)\n",
    " \n",
    "# Step 2: check if the model wanted to call a function\n",
    "if response.tool_calls:\n",
    "    tool_call = response.tool_calls[0]\n",
    " \n",
    "    # Step 3: call the function\n",
    "    function_name = tool_call[\"name\"]\n",
    "    function_to_call = available_functions[function_name]\n",
    "    function_args = tool_call[\"args\"]\n",
    "    # Step 4: send the info for each function call and function response to the model\n",
    "    function_response = function_to_call.invoke(function_args)\n",
    " \n",
    "    print(function_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8791f56-ebf8-456d-bb75-5ba2da34d833",
   "metadata": {},
   "source": [
    "#### with llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e51629d-3a05-42be-a5f3-b069b3c2f54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in San Francisco is 59°F.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import Sequence, List\n",
    " \n",
    "from llama_index.llms.upstage import Upstage\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.tools import BaseTool, FunctionTool\n",
    "from llama_index.core.agent import ReActAgent\n",
    " \n",
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"\n",
    "    return location's weather information\n",
    "    \"\"\"\n",
    "    weather_data = {\n",
    "        \"San Francisco\": {\"celsius\": \"15°C\", \"fahrenheit\": \"59°F\"},\n",
    "        \"Tokyo\": {\"celsius\": \"16°C\", \"fahrenheit\": \"61°F\"},\n",
    "        \"Paris\": {\"celsius\": \"11°C\", \"fahrenheit\": \"52°F\"},\n",
    "    }\n",
    "    return f\"The weather in {location} is {weather_data[location][unit]}.\"\n",
    " \n",
    "tool = FunctionTool.from_defaults(fn=get_current_weather)\n",
    "llm = Upstage()\n",
    " \n",
    "agent = ReActAgent.from_tools(\n",
    "    tools=[tool],\n",
    "    llm=llm,\n",
    ")\n",
    " \n",
    "response = agent.chat(\"How is the weather in San Francisco today?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed96dbda-dab7-4e7e-bcd7-673e95e2b476",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "\n",
    "Embed any text with Solar Embeddings API.\n",
    "\n",
    "The embeddings API converts text into numbers that computers can understand. Imagine converting a sentence into a list of numbers, each capturing a piece of the sentence's meaning. This makes it easier for machines to do tasks like finding similar texts, sorting information, or even answering questions.\n",
    "\n",
    "Solar Embeddings API features dual models, solar-embedding-1-large-query for user queries and solar-embedding-1-large-passage for document embedding, within a unified vector space, designed to enhance text processing tasks with a focus on performance.\n",
    "\n",
    "For developers building search engines or retrieval systems, solar-embedding-1-large-passage is ideal for initially embedding the searchable content. Upon user query submission, leveraging solar-embedding-1-large-query facilitates efficient and accurate matching of queries with the embedded content, thereby optimizing the information retrieval process.\n",
    "\n",
    "#### with http request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c14e0ebf-5378-4dec-8291-a155a9851d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between query and document: 0.3974243426178674\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from openai import OpenAI\n",
    " \n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"UPSTAGE_API_KEY\"),\n",
    "    base_url=\"https://api.upstage.ai/v1/solar\"\n",
    ")\n",
    " \n",
    "query_result = client.embeddings.create(\n",
    "    model = \"solar-embedding-1-large-query\",\n",
    "    input = \"What makes Solar LLM small yet effective?\"\n",
    ").data[0].embedding\n",
    " \n",
    "document_result = client.embeddings.create(\n",
    "    model = \"solar-embedding-1-large-passage\",\n",
    "    input = \"SOLAR 10.7B: Scaling Large Language Models with Simple yet Effective Depth Up-Scaling. DUS is simple yet effective in scaling up high performance LLMs from small ones. \"\n",
    ").data[0].embedding\n",
    " \n",
    "similarity = np.dot(np.array(query_result), np.array(document_result))\n",
    "print(f\"Similarity between query and document: {similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc40a82-7f96-4d10-ac93-9279bec40645",
   "metadata": {},
   "source": [
    "#### with langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0d59ae3-33fb-400f-939c-b7cda0e338b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between query and document: 0.3974243426178674\n"
     ]
    }
   ],
   "source": [
    "from langchain_upstage import UpstageEmbeddings\n",
    " \n",
    "embeddings = UpstageEmbeddings(\n",
    "  model=\"solar-embedding-1-large\"\n",
    ")\n",
    " \n",
    "doc_result = embeddings.embed_documents(\n",
    "    [\"SOLAR 10.7B: Scaling Large Language Models with Simple yet Effective Depth Up-Scaling.\", \"DUS is simple yet effective in scaling up high performance LLMs from small ones.\"]\n",
    ")\n",
    " \n",
    "query_result = embeddings.embed_query(\"What makes Solar LLM small yet effective?\")\n",
    "similarity = np.dot(np.array(query_result), np.array(document_result))\n",
    "print(f\"Similarity between query and document: {similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c81fca4-924f-4da2-9b45-768c75fd63cd",
   "metadata": {},
   "source": [
    "#### with llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "753a00d2-c715-4749-8cf1-fdf5709c9832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between query and document: 0.3974243426178674\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.upstage import UpstageEmbedding\n",
    " \n",
    "embeddings = UpstageEmbedding(\n",
    "    model=\"solar-embedding-1-large\"\n",
    ")\n",
    " \n",
    " \n",
    "doc_result = embeddings.get_text_embedding_batch(\n",
    "    [\"SOLAR 10.7B: Scaling Large Language Models with Simple yet Effective Depth Up-Scaling.\", \"DUS is simple yet effective in scaling up high performance LLMs from small ones.\"]\n",
    ")\n",
    " \n",
    "query_result = embeddings.get_query_embedding(\"What makes Solar LLM small yet effective?\")\n",
    "similarity = np.dot(np.array(query_result), np.array(document_result))\n",
    "print(f\"Similarity between query and document: {similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7280ecc7-af90-472c-b081-629e8baba379",
   "metadata": {},
   "source": [
    "# Layout Analysis\n",
    "\n",
    "Detect document elements from any document including tables and figures.\n",
    "\n",
    "*Example Image*\n",
    "\n",
    "![invoice.png](./data/invoice.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b28df0-61aa-48a7-861b-d5834ae49257",
   "metadata": {},
   "source": [
    "#### with http request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7e19a35-7692-4338-9831-b0ce7eae34db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'api': '1.1', 'billed_pages': 1, 'elements': [{'bounding_box': [{'x': 95, 'y': 75}, {'x': 333, 'y': 75}, {'x': 333, 'y': 129}, {'x': 95, 'y': 129}], 'category': 'paragraph', 'html': \"<p id='0' style='font-size:22px'>INVOICE</p>\", 'id': 0, 'page': 1, 'text': 'INVOICE'}, {'bounding_box': [{'x': 1110, 'y': 108}, {'x': 1306, 'y': 108}, {'x': 1306, 'y': 136}, {'x': 1110, 'y': 136}], 'category': 'header', 'html': \"<br><header id='1' style='font-size:14px'># INV-AJ355548</header>\", 'id': 1, 'page': 1, 'text': '# INV-AJ355548'}, {'bounding_box': [{'x': 806, 'y': 106}, {'x': 942, 'y': 106}, {'x': 942, 'y': 138}, {'x': 806, 'y': 138}], 'category': 'paragraph', 'html': \"<br><p id='2' style='font-size:18px'>Invoice ID</p>\", 'id': 2, 'page': 1, 'text': 'Invoice ID'}, {'bounding_box': [{'x': 93, 'y': 363}, {'x': 227, 'y': 363}, {'x': 227, 'y': 530}, {'x': 93, 'y': 530}], 'category': 'paragraph', 'html': \"<p id='3' style='font-size:18px'>Company<br>Upstage<br>Name<br>Lucy Park</p>\", 'id': 3, 'page': 1, 'text': 'Company\\nUpstage\\nName\\nLucy Park'}, {'bounding_box': [{'x': 1202, 'y': 172}, {'x': 1306, 'y': 172}, {'x': 1306, 'y': 205}, {'x': 1202, 'y': 205}], 'category': 'paragraph', 'html': \"<br><p id='4' style='font-size:20px'>9/7/1992</p>\", 'id': 4, 'page': 1, 'text': '9/7/1992'}, {'bounding_box': [{'x': 806, 'y': 172}, {'x': 975, 'y': 172}, {'x': 975, 'y': 204}, {'x': 806, 'y': 204}], 'category': 'paragraph', 'html': \"<br><p id='5' style='font-size:18px'>Invoice Date</p>\", 'id': 5, 'page': 1, 'text': 'Invoice Date'}, {'bounding_box': [{'x': 807, 'y': 293}, {'x': 1146, 'y': 293}, {'x': 1146, 'y': 331}, {'x': 807, 'y': 331}], 'category': 'paragraph', 'html': \"<p id='6' style='font-size:22px'>Service Details Form</p>\", 'id': 6, 'page': 1, 'text': 'Service Details Form'}, {'bounding_box': [{'x': 808, 'y': 367}, {'x': 890, 'y': 367}, {'x': 890, 'y': 396}, {'x': 808, 'y': 396}], 'category': 'paragraph', 'html': \"<p id='7' style='font-size:18px'>Name</p>\", 'id': 7, 'page': 1, 'text': 'Name'}, {'bounding_box': [{'x': 807, 'y': 406}, {'x': 920, 'y': 406}, {'x': 920, 'y': 434}, {'x': 807, 'y': 434}], 'category': 'paragraph', 'html': \"<br><p id='8' style='font-size:18px'>Sung Kim</p>\", 'id': 8, 'page': 1, 'text': 'Sung Kim'}, {'bounding_box': [{'x': 95, 'y': 559}, {'x': 206, 'y': 559}, {'x': 206, 'y': 586}, {'x': 95, 'y': 586}], 'category': 'paragraph', 'html': \"<p id='9' style='font-size:18px'>Address</p>\", 'id': 9, 'page': 1, 'text': 'Address'}, {'bounding_box': [{'x': 807, 'y': 468}, {'x': 1250, 'y': 468}, {'x': 1250, 'y': 577}, {'x': 807, 'y': 577}], 'category': 'paragraph', 'html': \"<br><p id='10' style='font-size:18px'>-00 'ess<br>Gwanggyojungang-ro 338, Gyeonggi-do,<br>Sanghyeon-dong, Suji-gu<br>Yongin-si, South Korea</p>\", 'id': 10, 'page': 1, 'text': \"-00 'ess\\nGwanggyojungang-ro 338, Gyeonggi-do,\\nSanghyeon-dong, Suji-gu\\nYongin-si, South Korea\"}, {'bounding_box': [{'x': 94, 'y': 596}, {'x': 558, 'y': 596}, {'x': 558, 'y': 710}, {'x': 94, 'y': 710}], 'category': 'paragraph', 'html': \"<br><p id='11' style='font-size:16px'>7 Pepper Wood Street, 130 Stone Corner<br>Terrace<br>Wilkes Barre, Pennsylvania, 18768<br>United States</p>\", 'id': 11, 'page': 1, 'text': '7 Pepper Wood Street, 130 Stone Corner\\nTerrace\\nWilkes Barre, Pennsylvania, 18768\\nUnited States'}, {'bounding_box': [{'x': 95, 'y': 735}, {'x': 170, 'y': 735}, {'x': 170, 'y': 763}, {'x': 95, 'y': 763}], 'category': 'paragraph', 'html': \"<br><p id='12' style='font-size:20px'>Email</p>\", 'id': 12, 'page': 1, 'text': 'Email'}, {'bounding_box': [{'x': 94, 'y': 772}, {'x': 403, 'y': 772}, {'x': 403, 'y': 800}, {'x': 94, 'y': 800}], 'category': 'paragraph', 'html': \"<br><p id='13' style='font-size:20px'>Ikitchenman0@arizona.edu</p>\", 'id': 13, 'page': 1, 'text': 'Ikitchenman0@arizona.edu'}, {'bounding_box': [{'x': 93, 'y': 917}, {'x': 349, 'y': 917}, {'x': 349, 'y': 950}, {'x': 93, 'y': 950}], 'category': 'paragraph', 'html': \"<p id='14' style='font-size:20px'>Additional Request</p>\", 'id': 14, 'page': 1, 'text': 'Additional Request'}, {'bounding_box': [{'x': 594, 'y': 915}, {'x': 1287, 'y': 915}, {'x': 1287, 'y': 1004}, {'x': 594, 'y': 1004}], 'category': 'paragraph', 'html': \"<br><p id='15' style='font-size:16px'>Vivamus vestibulum sagittis sapien. Cum sociis natoque<br>penatibus et magnis dis parturient montes, nascetur ridiculus<br>mus.</p>\", 'id': 15, 'page': 1, 'text': 'Vivamus vestibulum sagittis sapien. Cum sociis natoque\\npenatibus et magnis dis parturient montes, nascetur ridiculus\\nmus.'}, {'bounding_box': [{'x': 93, 'y': 1139}, {'x': 352, 'y': 1139}, {'x': 352, 'y': 1165}, {'x': 93, 'y': 1165}], 'category': 'paragraph', 'html': \"<p id='16' style='font-size:14px'>TERMS AND CONDITIONS</p>\", 'id': 16, 'page': 1, 'text': 'TERMS AND CONDITIONS'}, {'bounding_box': [{'x': 92, 'y': 1195}, {'x': 1297, 'y': 1195}, {'x': 1297, 'y': 1309}, {'x': 92, 'y': 1309}], 'category': 'paragraph', 'html': \"<p id='17' style='font-size:14px'>1. The Seller shall not be liable to the Buyer directly or indirectly for any loss or damage suffered by the Buyer.<br>2. The Seller warrants the product for one (1) year from the date of shipment.<br>3. Any purchase order received by the seller will be interpreted as accepting this offer and the sale offer in writing. The buyer may<br>purchase the product in this offer only under the Terms and Conditions of the Seller included in this offer.</p>\", 'id': 17, 'page': 1, 'text': '1. The Seller shall not be liable to the Buyer directly or indirectly for any loss or damage suffered by the Buyer.\\n2. The Seller warrants the product for one (1) year from the date of shipment.\\n3. Any purchase order received by the seller will be interpreted as accepting this offer and the sale offer in writing. The buyer may\\npurchase the product in this offer only under the Terms and Conditions of the Seller included in this offer.'}], 'html': \"<p id='0' style='font-size:22px'>INVOICE</p>\\n<br><header id='1' style='font-size:14px'># INV-AJ355548</header>\\n<br><p id='2' style='font-size:18px'>Invoice ID</p>\\n<p id='3' style='font-size:18px'>Company<br>Upstage<br>Name<br>Lucy Park</p>\\n<br><p id='4' style='font-size:20px'>9/7/1992</p>\\n<br><p id='5' style='font-size:18px'>Invoice Date</p>\\n<p id='6' style='font-size:22px'>Service Details Form</p>\\n<p id='7' style='font-size:18px'>Name</p>\\n<br><p id='8' style='font-size:18px'>Sung Kim</p>\\n<p id='9' style='font-size:18px'>Address</p>\\n<br><p id='10' style='font-size:18px'>-00 'ess<br>Gwanggyojungang-ro 338, Gyeonggi-do,<br>Sanghyeon-dong, Suji-gu<br>Yongin-si, South Korea</p>\\n<br><p id='11' style='font-size:16px'>7 Pepper Wood Street, 130 Stone Corner<br>Terrace<br>Wilkes Barre, Pennsylvania, 18768<br>United States</p>\\n<br><p id='12' style='font-size:20px'>Email</p>\\n<br><p id='13' style='font-size:20px'>Ikitchenman0@arizona.edu</p>\\n<p id='14' style='font-size:20px'>Additional Request</p>\\n<br><p id='15' style='font-size:16px'>Vivamus vestibulum sagittis sapien. Cum sociis natoque<br>penatibus et magnis dis parturient montes, nascetur ridiculus<br>mus.</p>\\n<p id='16' style='font-size:14px'>TERMS AND CONDITIONS</p>\\n<p id='17' style='font-size:14px'>1. The Seller shall not be liable to the Buyer directly or indirectly for any loss or damage suffered by the Buyer.<br>2. The Seller warrants the product for one (1) year from the date of shipment.<br>3. Any purchase order received by the seller will be interpreted as accepting this offer and the sale offer in writing. The buyer may<br>purchase the product in this offer only under the Terms and Conditions of the Seller included in this offer.</p>\", 'metadata': {'pages': [{'height': 1370, 'page': 1, 'width': 1406}]}, 'mimetype': 'multipart/form-data', 'model': 'layout-analysis-0.3.1', 'text': \"INVOICE\\n# INV-AJ355548\\nInvoice ID\\nCompany\\nUpstage\\nName\\nLucy Park\\n9/7/1992\\nInvoice Date\\nService Details Form\\nName\\nSung Kim\\nAddress\\n-00 'ess\\nGwanggyojungang-ro 338, Gyeonggi-do,\\nSanghyeon-dong, Suji-gu\\nYongin-si, South Korea\\n7 Pepper Wood Street, 130 Stone Corner\\nTerrace\\nWilkes Barre, Pennsylvania, 18768\\nUnited States\\nEmail\\nIkitchenman0@arizona.edu\\nAdditional Request\\nVivamus vestibulum sagittis sapien. Cum sociis natoque\\npenatibus et magnis dis parturient montes, nascetur ridiculus\\nmus.\\nTERMS AND CONDITIONS\\n1. The Seller shall not be liable to the Buyer directly or indirectly for any loss or damage suffered by the Buyer.\\n2. The Seller warrants the product for one (1) year from the date of shipment.\\n3. Any purchase order received by the seller will be interpreted as accepting this offer and the sale offer in writing. The buyer may\\npurchase the product in this offer only under the Terms and Conditions of the Seller included in this offer.\"}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    " \n",
    "api_key = os.environ.get(\"UPSTAGE_API_KEY\")\n",
    "filename = \"data/invoice.png\"\n",
    " \n",
    "url = \"https://api.upstage.ai/v1/document-ai/layout-analysis\"\n",
    "headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "files = {\"document\": open(filename, \"rb\")}\n",
    "data = {\"ocr\": True}\n",
    "response = requests.post(url, headers=headers, files=files, data=data)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e95bf2-438e-468f-8baa-6239d9f7c3d0",
   "metadata": {},
   "source": [
    "#### with langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb9a9aba-d68e-4937-840f-8b607c37a212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain-upstage                       0.1.6rc2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep langchain-upstage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "141f5b84-6014-4148-b9dd-f220aad0d646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=\"<p id='0' style='font-size:22px'>INVOICE</p> <br><p id='2' style='font-size:18px'>Invoice ID</p> <p id='3' style='font-size:18px'>Company<br>Upstage<br>Name<br>Lucy Park</p> <br><p id='4' style='font-size:20px'>9/7/1992</p> <br><p id='5' style='font-size:18px'>Invoice Date</p> <p id='6' style='font-size:22px'>Service Details Form</p> <p id='7' style='font-size:18px'>Name</p> <br><p id='8' style='font-size:18px'>Sung Kim</p> <p id='9' style='font-size:18px'>Address</p> <br><p id='10' style='font-size:18px'>-00 'ess<br>Gwanggyojungang-ro 338, Gyeonggi-do,<br>Sanghyeon-dong, Suji-gu<br>Yongin-si, South Korea</p> <br><p id='11' style='font-size:16px'>7 Pepper Wood Street, 130 Stone Corner<br>Terrace<br>Wilkes Barre, Pennsylvania, 18768<br>United States</p> <br><p id='12' style='font-size:20px'>Email</p> <br><p id='13' style='font-size:20px'>Ikitchenman0@arizona.edu</p> <p id='14' style='font-size:20px'>Additional Request</p> <br><p id='15' style='font-size:16px'>Vivamus vestibulum sagittis sapien. Cum sociis natoque<br>penatibus et magnis dis parturient montes, nascetur ridiculus<br>mus.</p> <p id='16' style='font-size:14px'>TERMS AND CONDITIONS</p> <p id='17' style='font-size:14px'>1. The Seller shall not be liable to the Buyer directly or indirectly for any loss or damage suffered by the Buyer.<br>2. The Seller warrants the product for one (1) year from the date of shipment.<br>3. Any purchase order received by the seller will be interpreted as accepting this offer and the sale offer in writing. The buyer may<br>purchase the product in this offer only under the Terms and Conditions of the Seller included in this offer.</p>\" metadata={'page': 1}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_upstage import UpstageLayoutAnalysisLoader\n",
    "\n",
    "file_path = \"data/invoice.png\"\n",
    "loader = UpstageLayoutAnalysisLoader(file_path, split=\"page\", use_ocr=True)\n",
    "\n",
    "pages = loader.load()  # or loader.lazy_load()\n",
    "for page in pages:\n",
    "    print(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed50221d-08d2-46fd-9835-e651d6c632c8",
   "metadata": {},
   "source": [
    "# Key Information Extraction\n",
    "\n",
    "Extract key information from target documents.\n",
    "\n",
    "Will use same invoice.png example image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07d4aed3-1686-4d41-a457-6ab0ba1c5bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'apiVersion': '1.1', 'confidence': 0.5562, 'documentType': 'receipt', 'fields': [{'confidence': 0.7508, 'id': 0, 'key': 'store.store_name', 'refinedValue': 'Company', 'type': 'header', 'value': 'Company'}, {'confidence': 0.1591, 'id': 1, 'key': 'store.store_registration_number', 'refinedValue': 'Up', 'type': 'header', 'value': 'Up'}, {'confidence': 0.04, 'id': 2, 'key': 'store.store_name', 'refinedValue': 'Su Kim', 'type': 'content', 'value': 'Su Kim'}, {'confidence': 0.9652, 'id': 3, 'key': 'store.store_address', 'refinedValue': 'Lucy Park', 'type': 'content', 'value': 'Lucy Park'}, {'confidence': 0.9685, 'id': 4, 'key': 'store.store_phone_number', 'refinedValue': 'Email', 'type': 'header', 'value': 'Email'}], 'metadata': {'pages': [{'height': 1370, 'page': 1, 'width': 1406}]}, 'mimeType': 'multipart/form-data', 'modelVersion': 'receipt-extraction-3.2.0', 'numBilledPages': 1, 'stored': True}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "api_key = os.environ.get(\"UPSTAGE_API_KEY\")\n",
    "filename = \"data/invoice.png\"\n",
    "model = \"receipt-extraction\"\n",
    "\n",
    "url = f\"https://api.upstage.ai/v1/document-ai/extraction\"\n",
    "headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "files = {\"document\": open(filename, \"rb\")}\n",
    "data = {\"model\": model}\n",
    "response = requests.post(url, headers=headers, files=files, data=data)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac1ae21-484f-4a02-8959-cc06a4531147",
   "metadata": {},
   "source": [
    "# Document OCR\n",
    "\n",
    "Extract all text from any document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3812ea44-598c-463b-991f-70ad71faa9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'apiVersion': '1.1', 'confidence': 0.9939, 'metadata': {'pages': [{'height': 1370, 'page': 1, 'width': 1406}]}, 'mimeType': 'multipart/form-data', 'modelVersion': 'ocr-2.2.1', 'numBilledPages': 1, 'pages': [{'confidence': 0.9939, 'height': 1370, 'id': 0, 'text': \"INVOICE # INV-AJ355548 \\nInvoice ID \\nInvoice Date 9/7/1992 \\nService Details Form \\nCompany Name \\nUpstage Sung Kim \\nName -00 'ess \\nLucy Park Gwanggyojungang-ro 338, Gyeonggi-do, \\nSanghyeon-dong, Suji-gu \\nYongin-si, South Korea \\nAddress \\n7 Pepper Wood Street, 130 Stone Corner \\nTerrace \\nWilkes Barre, Pennsylvania, 18768 \\nUnited States \\nEmail \\nIkitchenman0@arizona.edu \\nAdditional Request Vivamus vestibulum sagittis sapien. Cum sociis natoque \\npenatibus et magnis dis parturient montes, nascetur ridiculus \\nmus. \\nTERMS AND CONDITIONS \\n1. The Seller shall not be liable to the Buyer directly or indirectly for any loss or damage suffered by the Buyer. \\n2. The Seller warrants the product for one (1) year from the date of shipment. \\n3. Any purchase order received by the seller will be interpreted as accepting this offer and the sale offer in writing. The buyer may \\npurchase the product in this offer only under the Terms and Conditions of the Seller included in this offer.\", 'width': 1406, 'words': [{'boundingBox': {'vertices': [{'x': 98, 'y': 79}, {'x': 331, 'y': 79}, {'x': 331, 'y': 126}, {'x': 98, 'y': 126}]}, 'confidence': 0.9967, 'id': 0, 'text': 'INVOICE'}, {'boundingBox': {'vertices': [{'x': 1113, 'y': 111}, {'x': 1130, 'y': 111}, {'x': 1130, 'y': 132}, {'x': 1113, 'y': 132}]}, 'confidence': 0.9958, 'id': 1, 'text': '#'}, {'boundingBox': {'vertices': [{'x': 1134, 'y': 111}, {'x': 1304, 'y': 111}, {'x': 1304, 'y': 133}, {'x': 1134, 'y': 133}]}, 'confidence': 0.9991, 'id': 2, 'text': 'INV-AJ355548'}, {'boundingBox': {'vertices': [{'x': 810, 'y': 108}, {'x': 906, 'y': 108}, {'x': 906, 'y': 135}, {'x': 810, 'y': 135}]}, 'confidence': 0.9912, 'id': 3, 'text': 'Invoice'}, {'boundingBox': {'vertices': [{'x': 909, 'y': 109}, {'x': 940, 'y': 109}, {'x': 940, 'y': 135}, {'x': 909, 'y': 135}]}, 'confidence': 0.9969, 'id': 4, 'text': 'ID'}, {'boundingBox': {'vertices': [{'x': 810, 'y': 173}, {'x': 906, 'y': 173}, {'x': 906, 'y': 200}, {'x': 810, 'y': 200}]}, 'confidence': 0.9922, 'id': 5, 'text': 'Invoice'}, {'boundingBox': {'vertices': [{'x': 910, 'y': 175}, {'x': 973, 'y': 175}, {'x': 973, 'y': 200}, {'x': 910, 'y': 200}]}, 'confidence': 0.9954, 'id': 6, 'text': 'Date'}, {'boundingBox': {'vertices': [{'x': 1204, 'y': 174}, {'x': 1305, 'y': 174}, {'x': 1305, 'y': 202}, {'x': 1204, 'y': 202}]}, 'confidence': 0.9967, 'id': 7, 'text': '9/7/1992'}, {'boundingBox': {'vertices': [{'x': 811, 'y': 295}, {'x': 934, 'y': 295}, {'x': 934, 'y': 326}, {'x': 811, 'y': 327}]}, 'confidence': 0.9975, 'id': 8, 'text': 'Service'}, {'boundingBox': {'vertices': [{'x': 941, 'y': 295}, {'x': 1053, 'y': 295}, {'x': 1053, 'y': 326}, {'x': 941, 'y': 326}]}, 'confidence': 0.9944, 'id': 9, 'text': 'Details'}, {'boundingBox': {'vertices': [{'x': 1060, 'y': 297}, {'x': 1144, 'y': 297}, {'x': 1143, 'y': 326}, {'x': 1060, 'y': 326}]}, 'confidence': 0.9943, 'id': 10, 'text': 'Form'}, {'boundingBox': {'vertices': [{'x': 97, 'y': 368}, {'x': 222, 'y': 368}, {'x': 222, 'y': 397}, {'x': 97, 'y': 397}]}, 'confidence': 0.9977, 'id': 11, 'text': 'Company'}, {'boundingBox': {'vertices': [{'x': 811, 'y': 369}, {'x': 889, 'y': 369}, {'x': 889, 'y': 393}, {'x': 811, 'y': 393}]}, 'confidence': 0.9984, 'id': 12, 'text': 'Name'}, {'boundingBox': {'vertices': [{'x': 97, 'y': 408}, {'x': 192, 'y': 408}, {'x': 192, 'y': 435}, {'x': 97, 'y': 435}]}, 'confidence': 0.9986, 'id': 13, 'text': 'Upstage'}, {'boundingBox': {'vertices': [{'x': 810, 'y': 408}, {'x': 870, 'y': 408}, {'x': 869, 'y': 435}, {'x': 809, 'y': 434}]}, 'confidence': 0.9933, 'id': 14, 'text': 'Sung'}, {'boundingBox': {'vertices': [{'x': 873, 'y': 409}, {'x': 917, 'y': 409}, {'x': 917, 'y': 430}, {'x': 873, 'y': 430}]}, 'confidence': 0.9973, 'id': 15, 'text': 'Kim'}, {'boundingBox': {'vertices': [{'x': 98, 'y': 462}, {'x': 174, 'y': 462}, {'x': 174, 'y': 485}, {'x': 98, 'y': 485}]}, 'confidence': 0.9701, 'id': 16, 'text': 'Name'}, {'boundingBox': {'vertices': [{'x': 814, 'y': 469}, {'x': 861, 'y': 471}, {'x': 860, 'y': 492}, {'x': 813, 'y': 489}]}, 'confidence': 0.9159, 'id': 17, 'text': '-00'}, {'boundingBox': {'vertices': [{'x': 867, 'y': 470}, {'x': 921, 'y': 471}, {'x': 920, 'y': 492}, {'x': 867, 'y': 491}]}, 'confidence': 0.8849, 'id': 18, 'text': \"'ess\"}, {'boundingBox': {'vertices': [{'x': 96, 'y': 499}, {'x': 151, 'y': 500}, {'x': 150, 'y': 527}, {'x': 96, 'y': 526}]}, 'confidence': 0.9922, 'id': 19, 'text': 'Lucy'}, {'boundingBox': {'vertices': [{'x': 154, 'y': 500}, {'x': 206, 'y': 499}, {'x': 207, 'y': 522}, {'x': 155, 'y': 523}]}, 'confidence': 0.9965, 'id': 20, 'text': 'Park'}, {'boundingBox': {'vertices': [{'x': 810, 'y': 495}, {'x': 1045, 'y': 496}, {'x': 1045, 'y': 524}, {'x': 810, 'y': 524}]}, 'confidence': 0.9946, 'id': 21, 'text': 'Gwanggyojungang-ro'}, {'boundingBox': {'vertices': [{'x': 1046, 'y': 495}, {'x': 1097, 'y': 495}, {'x': 1096, 'y': 520}, {'x': 1046, 'y': 519}]}, 'confidence': 0.9979, 'id': 22, 'text': '338,'}, {'boundingBox': {'vertices': [{'x': 1101, 'y': 494}, {'x': 1248, 'y': 494}, {'x': 1248, 'y': 522}, {'x': 1101, 'y': 522}]}, 'confidence': 0.9863, 'id': 23, 'text': 'Gyeonggi-do,'}, {'boundingBox': {'vertices': [{'x': 810, 'y': 522}, {'x': 1004, 'y': 523}, {'x': 1004, 'y': 549}, {'x': 810, 'y': 549}]}, 'confidence': 0.9903, 'id': 24, 'text': 'Sanghyeon-dong,'}, {'boundingBox': {'vertices': [{'x': 1007, 'y': 522}, {'x': 1085, 'y': 522}, {'x': 1085, 'y': 549}, {'x': 1007, 'y': 549}]}, 'confidence': 0.9986, 'id': 25, 'text': 'Suji-gu'}, {'boundingBox': {'vertices': [{'x': 810, 'y': 549}, {'x': 918, 'y': 549}, {'x': 918, 'y': 575}, {'x': 810, 'y': 575}]}, 'confidence': 0.9943, 'id': 26, 'text': 'Yongin-si,'}, {'boundingBox': {'vertices': [{'x': 922, 'y': 549}, {'x': 988, 'y': 549}, {'x': 988, 'y': 572}, {'x': 922, 'y': 572}]}, 'confidence': 0.9988, 'id': 27, 'text': 'South'}, {'boundingBox': {'vertices': [{'x': 991, 'y': 549}, {'x': 1058, 'y': 549}, {'x': 1058, 'y': 572}, {'x': 991, 'y': 572}]}, 'confidence': 0.9988, 'id': 28, 'text': 'Korea'}, {'boundingBox': {'vertices': [{'x': 98, 'y': 560}, {'x': 207, 'y': 560}, {'x': 207, 'y': 584}, {'x': 98, 'y': 584}]}, 'confidence': 0.9967, 'id': 29, 'text': 'Address'}, {'boundingBox': {'vertices': [{'x': 97, 'y': 600}, {'x': 112, 'y': 600}, {'x': 112, 'y': 621}, {'x': 97, 'y': 621}]}, 'confidence': 0.9903, 'id': 30, 'text': '7'}, {'boundingBox': {'vertices': [{'x': 118, 'y': 600}, {'x': 199, 'y': 600}, {'x': 199, 'y': 624}, {'x': 118, 'y': 624}]}, 'confidence': 0.9948, 'id': 31, 'text': 'Pepper'}, {'boundingBox': {'vertices': [{'x': 204, 'y': 599}, {'x': 270, 'y': 599}, {'x': 270, 'y': 622}, {'x': 204, 'y': 622}]}, 'confidence': 0.9955, 'id': 32, 'text': 'Wood'}, {'boundingBox': {'vertices': [{'x': 274, 'y': 599}, {'x': 352, 'y': 600}, {'x': 352, 'y': 625}, {'x': 274, 'y': 624}]}, 'confidence': 0.9934, 'id': 33, 'text': 'Street,'}, {'boundingBox': {'vertices': [{'x': 356, 'y': 599}, {'x': 399, 'y': 599}, {'x': 399, 'y': 622}, {'x': 356, 'y': 622}]}, 'confidence': 0.9977, 'id': 34, 'text': '130'}, {'boundingBox': {'vertices': [{'x': 404, 'y': 599}, {'x': 471, 'y': 601}, {'x': 470, 'y': 624}, {'x': 403, 'y': 622}]}, 'confidence': 0.9963, 'id': 35, 'text': 'Stone'}, {'boundingBox': {'vertices': [{'x': 476, 'y': 600}, {'x': 556, 'y': 601}, {'x': 555, 'y': 623}, {'x': 476, 'y': 622}]}, 'confidence': 0.9981, 'id': 36, 'text': 'Corner'}, {'boundingBox': {'vertices': [{'x': 97, 'y': 628}, {'x': 183, 'y': 628}, {'x': 183, 'y': 652}, {'x': 97, 'y': 652}]}, 'confidence': 0.9979, 'id': 37, 'text': 'Terrace'}, {'boundingBox': {'vertices': [{'x': 98, 'y': 656}, {'x': 172, 'y': 656}, {'x': 172, 'y': 678}, {'x': 98, 'y': 678}]}, 'confidence': 0.9969, 'id': 38, 'text': 'Wilkes'}, {'boundingBox': {'vertices': [{'x': 177, 'y': 655}, {'x': 246, 'y': 657}, {'x': 246, 'y': 682}, {'x': 176, 'y': 680}]}, 'confidence': 0.9816, 'id': 39, 'text': 'Barre,'}, {'boundingBox': {'vertices': [{'x': 250, 'y': 655}, {'x': 404, 'y': 655}, {'x': 404, 'y': 682}, {'x': 250, 'y': 682}]}, 'confidence': 0.9909, 'id': 40, 'text': 'Pennsylvania,'}, {'boundingBox': {'vertices': [{'x': 409, 'y': 655}, {'x': 481, 'y': 655}, {'x': 481, 'y': 677}, {'x': 409, 'y': 677}]}, 'confidence': 0.9993, 'id': 41, 'text': '18768'}, {'boundingBox': {'vertices': [{'x': 97, 'y': 682}, {'x': 173, 'y': 682}, {'x': 173, 'y': 705}, {'x': 97, 'y': 705}]}, 'confidence': 0.9984, 'id': 42, 'text': 'United'}, {'boundingBox': {'vertices': [{'x': 177, 'y': 683}, {'x': 250, 'y': 683}, {'x': 250, 'y': 705}, {'x': 177, 'y': 705}]}, 'confidence': 0.9982, 'id': 43, 'text': 'States'}, {'boundingBox': {'vertices': [{'x': 97, 'y': 735}, {'x': 170, 'y': 735}, {'x': 170, 'y': 761}, {'x': 97, 'y': 761}]}, 'confidence': 0.9957, 'id': 44, 'text': 'Email'}, {'boundingBox': {'vertices': [{'x': 95, 'y': 773}, {'x': 402, 'y': 773}, {'x': 402, 'y': 800}, {'x': 95, 'y': 800}]}, 'confidence': 0.9786, 'id': 45, 'text': 'Ikitchenman0@arizona.edu'}, {'boundingBox': {'vertices': [{'x': 97, 'y': 918}, {'x': 232, 'y': 918}, {'x': 232, 'y': 946}, {'x': 97, 'y': 946}]}, 'confidence': 0.9958, 'id': 46, 'text': 'Additional'}, {'boundingBox': {'vertices': [{'x': 236, 'y': 921}, {'x': 346, 'y': 920}, {'x': 346, 'y': 949}, {'x': 236, 'y': 950}]}, 'confidence': 0.9982, 'id': 47, 'text': 'Request'}, {'boundingBox': {'vertices': [{'x': 597, 'y': 921}, {'x': 694, 'y': 921}, {'x': 694, 'y': 944}, {'x': 597, 'y': 944}]}, 'confidence': 0.9983, 'id': 48, 'text': 'Vivamus'}, {'boundingBox': {'vertices': [{'x': 699, 'y': 921}, {'x': 822, 'y': 921}, {'x': 822, 'y': 944}, {'x': 699, 'y': 944}]}, 'confidence': 0.9964, 'id': 49, 'text': 'vestibulum'}, {'boundingBox': {'vertices': [{'x': 826, 'y': 921}, {'x': 911, 'y': 920}, {'x': 911, 'y': 946}, {'x': 826, 'y': 947}]}, 'confidence': 0.9911, 'id': 50, 'text': 'sagittis'}, {'boundingBox': {'vertices': [{'x': 913, 'y': 920}, {'x': 997, 'y': 919}, {'x': 997, 'y': 946}, {'x': 914, 'y': 947}]}, 'confidence': 0.9935, 'id': 51, 'text': 'sapien.'}, {'boundingBox': {'vertices': [{'x': 1001, 'y': 921}, {'x': 1055, 'y': 921}, {'x': 1055, 'y': 943}, {'x': 1001, 'y': 943}]}, 'confidence': 0.998, 'id': 52, 'text': 'Cum'}, {'boundingBox': {'vertices': [{'x': 1059, 'y': 921}, {'x': 1125, 'y': 921}, {'x': 1125, 'y': 944}, {'x': 1059, 'y': 944}]}, 'confidence': 0.9892, 'id': 53, 'text': 'sociis'}, {'boundingBox': {'vertices': [{'x': 1129, 'y': 922}, {'x': 1223, 'y': 922}, {'x': 1223, 'y': 946}, {'x': 1129, 'y': 946}]}, 'confidence': 0.9972, 'id': 54, 'text': 'natoque'}, {'boundingBox': {'vertices': [{'x': 597, 'y': 949}, {'x': 709, 'y': 947}, {'x': 710, 'y': 971}, {'x': 598, 'y': 973}]}, 'confidence': 0.9975, 'id': 55, 'text': 'penatibus'}, {'boundingBox': {'vertices': [{'x': 714, 'y': 950}, {'x': 739, 'y': 950}, {'x': 739, 'y': 971}, {'x': 715, 'y': 971}]}, 'confidence': 0.9917, 'id': 56, 'text': 'et'}, {'boundingBox': {'vertices': [{'x': 743, 'y': 949}, {'x': 826, 'y': 948}, {'x': 826, 'y': 974}, {'x': 743, 'y': 975}]}, 'confidence': 0.9963, 'id': 57, 'text': 'magnis'}, {'boundingBox': {'vertices': [{'x': 829, 'y': 949}, {'x': 865, 'y': 948}, {'x': 865, 'y': 970}, {'x': 830, 'y': 971}]}, 'confidence': 0.9975, 'id': 58, 'text': 'dis'}, {'boundingBox': {'vertices': [{'x': 869, 'y': 948}, {'x': 983, 'y': 947}, {'x': 983, 'y': 973}, {'x': 869, 'y': 974}]}, 'confidence': 0.993, 'id': 59, 'text': 'parturient'}, {'boundingBox': {'vertices': [{'x': 986, 'y': 950}, {'x': 1078, 'y': 950}, {'x': 1078, 'y': 973}, {'x': 986, 'y': 973}]}, 'confidence': 0.988, 'id': 60, 'text': 'montes,'}, {'boundingBox': {'vertices': [{'x': 1082, 'y': 951}, {'x': 1183, 'y': 948}, {'x': 1183, 'y': 970}, {'x': 1082, 'y': 973}]}, 'confidence': 0.9968, 'id': 61, 'text': 'nascetur'}, {'boundingBox': {'vertices': [{'x': 1185, 'y': 948}, {'x': 1284, 'y': 948}, {'x': 1284, 'y': 971}, {'x': 1185, 'y': 971}]}, 'confidence': 0.997, 'id': 62, 'text': 'ridiculus'}, {'boundingBox': {'vertices': [{'x': 598, 'y': 980}, {'x': 654, 'y': 980}, {'x': 654, 'y': 1000}, {'x': 598, 'y': 1000}]}, 'confidence': 0.9912, 'id': 63, 'text': 'mus.'}, {'boundingBox': {'vertices': [{'x': 97, 'y': 1141}, {'x': 169, 'y': 1141}, {'x': 169, 'y': 1162}, {'x': 97, 'y': 1162}]}, 'confidence': 0.9985, 'id': 64, 'text': 'TERMS'}, {'boundingBox': {'vertices': [{'x': 172, 'y': 1142}, {'x': 217, 'y': 1142}, {'x': 217, 'y': 1162}, {'x': 172, 'y': 1162}]}, 'confidence': 0.9969, 'id': 65, 'text': 'AND'}, {'boundingBox': {'vertices': [{'x': 220, 'y': 1141}, {'x': 350, 'y': 1141}, {'x': 350, 'y': 1162}, {'x': 220, 'y': 1162}]}, 'confidence': 0.9969, 'id': 66, 'text': 'CONDITIONS'}, {'boundingBox': {'vertices': [{'x': 96, 'y': 1199}, {'x': 114, 'y': 1199}, {'x': 114, 'y': 1217}, {'x': 96, 'y': 1217}]}, 'confidence': 0.9804, 'id': 67, 'text': '1.'}, {'boundingBox': {'vertices': [{'x': 117, 'y': 1198}, {'x': 154, 'y': 1198}, {'x': 154, 'y': 1218}, {'x': 117, 'y': 1218}]}, 'confidence': 0.9993, 'id': 68, 'text': 'The'}, {'boundingBox': {'vertices': [{'x': 157, 'y': 1198}, {'x': 213, 'y': 1198}, {'x': 213, 'y': 1217}, {'x': 157, 'y': 1217}]}, 'confidence': 0.9948, 'id': 69, 'text': 'Seller'}, {'boundingBox': {'vertices': [{'x': 215, 'y': 1198}, {'x': 260, 'y': 1198}, {'x': 260, 'y': 1217}, {'x': 215, 'y': 1217}]}, 'confidence': 0.9944, 'id': 70, 'text': 'shall'}, {'boundingBox': {'vertices': [{'x': 263, 'y': 1199}, {'x': 296, 'y': 1199}, {'x': 296, 'y': 1217}, {'x': 263, 'y': 1217}]}, 'confidence': 0.996, 'id': 71, 'text': 'not'}, {'boundingBox': {'vertices': [{'x': 299, 'y': 1198}, {'x': 324, 'y': 1198}, {'x': 324, 'y': 1217}, {'x': 299, 'y': 1217}]}, 'confidence': 0.9984, 'id': 72, 'text': 'be'}, {'boundingBox': {'vertices': [{'x': 326, 'y': 1198}, {'x': 378, 'y': 1198}, {'x': 378, 'y': 1217}, {'x': 326, 'y': 1217}]}, 'confidence': 0.9983, 'id': 73, 'text': 'liable'}, {'boundingBox': {'vertices': [{'x': 381, 'y': 1200}, {'x': 403, 'y': 1200}, {'x': 403, 'y': 1217}, {'x': 381, 'y': 1217}]}, 'confidence': 0.9902, 'id': 74, 'text': 'to'}, {'boundingBox': {'vertices': [{'x': 405, 'y': 1199}, {'x': 438, 'y': 1199}, {'x': 438, 'y': 1217}, {'x': 405, 'y': 1217}]}, 'confidence': 0.9996, 'id': 75, 'text': 'the'}, {'boundingBox': {'vertices': [{'x': 442, 'y': 1199}, {'x': 497, 'y': 1200}, {'x': 496, 'y': 1220}, {'x': 441, 'y': 1220}]}, 'confidence': 0.9961, 'id': 76, 'text': 'Buyer'}, {'boundingBox': {'vertices': [{'x': 499, 'y': 1198}, {'x': 571, 'y': 1199}, {'x': 571, 'y': 1220}, {'x': 499, 'y': 1219}]}, 'confidence': 0.9937, 'id': 77, 'text': 'directly'}, {'boundingBox': {'vertices': [{'x': 574, 'y': 1201}, {'x': 597, 'y': 1201}, {'x': 596, 'y': 1217}, {'x': 574, 'y': 1217}]}, 'confidence': 0.9945, 'id': 78, 'text': 'or'}, {'boundingBox': {'vertices': [{'x': 598, 'y': 1197}, {'x': 687, 'y': 1199}, {'x': 686, 'y': 1220}, {'x': 597, 'y': 1218}]}, 'confidence': 0.9934, 'id': 79, 'text': 'indirectly'}, {'boundingBox': {'vertices': [{'x': 689, 'y': 1198}, {'x': 719, 'y': 1198}, {'x': 719, 'y': 1217}, {'x': 689, 'y': 1217}]}, 'confidence': 0.999, 'id': 80, 'text': 'for'}, {'boundingBox': {'vertices': [{'x': 721, 'y': 1201}, {'x': 756, 'y': 1201}, {'x': 756, 'y': 1220}, {'x': 721, 'y': 1220}]}, 'confidence': 0.996, 'id': 81, 'text': 'any'}, {'boundingBox': {'vertices': [{'x': 758, 'y': 1199}, {'x': 799, 'y': 1200}, {'x': 798, 'y': 1218}, {'x': 758, 'y': 1217}]}, 'confidence': 0.9975, 'id': 82, 'text': 'loss'}, {'boundingBox': {'vertices': [{'x': 801, 'y': 1201}, {'x': 823, 'y': 1201}, {'x': 823, 'y': 1217}, {'x': 801, 'y': 1217}]}, 'confidence': 0.9875, 'id': 83, 'text': 'or'}, {'boundingBox': {'vertices': [{'x': 826, 'y': 1198}, {'x': 902, 'y': 1200}, {'x': 901, 'y': 1221}, {'x': 826, 'y': 1219}]}, 'confidence': 0.9992, 'id': 84, 'text': 'damage'}, {'boundingBox': {'vertices': [{'x': 905, 'y': 1198}, {'x': 985, 'y': 1198}, {'x': 985, 'y': 1218}, {'x': 905, 'y': 1218}]}, 'confidence': 0.9977, 'id': 85, 'text': 'suffered'}, {'boundingBox': {'vertices': [{'x': 988, 'y': 1199}, {'x': 1012, 'y': 1199}, {'x': 1012, 'y': 1220}, {'x': 987, 'y': 1220}]}, 'confidence': 0.9991, 'id': 86, 'text': 'by'}, {'boundingBox': {'vertices': [{'x': 1015, 'y': 1199}, {'x': 1048, 'y': 1199}, {'x': 1048, 'y': 1217}, {'x': 1015, 'y': 1217}]}, 'confidence': 0.9994, 'id': 87, 'text': 'the'}, {'boundingBox': {'vertices': [{'x': 1051, 'y': 1199}, {'x': 1111, 'y': 1199}, {'x': 1111, 'y': 1220}, {'x': 1051, 'y': 1220}]}, 'confidence': 0.9944, 'id': 88, 'text': 'Buyer.'}, {'boundingBox': {'vertices': [{'x': 96, 'y': 1226}, {'x': 116, 'y': 1225}, {'x': 117, 'y': 1244}, {'x': 96, 'y': 1245}]}, 'confidence': 0.9933, 'id': 89, 'text': '2.'}, {'boundingBox': {'vertices': [{'x': 120, 'y': 1225}, {'x': 157, 'y': 1225}, {'x': 157, 'y': 1245}, {'x': 120, 'y': 1245}]}, 'confidence': 0.9994, 'id': 90, 'text': 'The'}, {'boundingBox': {'vertices': [{'x': 160, 'y': 1225}, {'x': 215, 'y': 1225}, {'x': 215, 'y': 1245}, {'x': 160, 'y': 1245}]}, 'confidence': 0.995, 'id': 91, 'text': 'Seller'}, {'boundingBox': {'vertices': [{'x': 219, 'y': 1227}, {'x': 301, 'y': 1227}, {'x': 301, 'y': 1245}, {'x': 219, 'y': 1245}]}, 'confidence': 0.9857, 'id': 92, 'text': 'warrants'}, {'boundingBox': {'vertices': [{'x': 303, 'y': 1227}, {'x': 336, 'y': 1227}, {'x': 336, 'y': 1245}, {'x': 303, 'y': 1245}]}, 'confidence': 0.9994, 'id': 93, 'text': 'the'}, {'boundingBox': {'vertices': [{'x': 339, 'y': 1227}, {'x': 414, 'y': 1226}, {'x': 414, 'y': 1246}, {'x': 339, 'y': 1247}]}, 'confidence': 0.9971, 'id': 94, 'text': 'product'}, {'boundingBox': {'vertices': [{'x': 416, 'y': 1225}, {'x': 446, 'y': 1225}, {'x': 446, 'y': 1245}, {'x': 416, 'y': 1245}]}, 'confidence': 0.9982, 'id': 95, 'text': 'for'}, {'boundingBox': {'vertices': [{'x': 448, 'y': 1228}, {'x': 484, 'y': 1228}, {'x': 484, 'y': 1245}, {'x': 448, 'y': 1245}]}, 'confidence': 0.9987, 'id': 96, 'text': 'one'}, {'boundingBox': {'vertices': [{'x': 488, 'y': 1226}, {'x': 514, 'y': 1226}, {'x': 514, 'y': 1246}, {'x': 488, 'y': 1246}]}, 'confidence': 0.9943, 'id': 97, 'text': '(1)'}, {'boundingBox': {'vertices': [{'x': 517, 'y': 1229}, {'x': 560, 'y': 1228}, {'x': 560, 'y': 1246}, {'x': 517, 'y': 1247}]}, 'confidence': 0.998, 'id': 98, 'text': 'year'}, {'boundingBox': {'vertices': [{'x': 562, 'y': 1225}, {'x': 607, 'y': 1225}, {'x': 607, 'y': 1245}, {'x': 562, 'y': 1245}]}, 'confidence': 0.9988, 'id': 99, 'text': 'from'}, {'boundingBox': {'vertices': [{'x': 610, 'y': 1226}, {'x': 643, 'y': 1226}, {'x': 643, 'y': 1244}, {'x': 610, 'y': 1244}]}, 'confidence': 0.9993, 'id': 100, 'text': 'the'}, {'boundingBox': {'vertices': [{'x': 646, 'y': 1226}, {'x': 690, 'y': 1228}, {'x': 689, 'y': 1246}, {'x': 645, 'y': 1244}]}, 'confidence': 0.9832, 'id': 101, 'text': 'date'}, {'boundingBox': {'vertices': [{'x': 692, 'y': 1226}, {'x': 713, 'y': 1225}, {'x': 714, 'y': 1245}, {'x': 693, 'y': 1245}]}, 'confidence': 0.9968, 'id': 102, 'text': 'of'}, {'boundingBox': {'vertices': [{'x': 716, 'y': 1226}, {'x': 809, 'y': 1225}, {'x': 809, 'y': 1246}, {'x': 716, 'y': 1247}]}, 'confidence': 0.9907, 'id': 103, 'text': 'shipment.'}, {'boundingBox': {'vertices': [{'x': 96, 'y': 1253}, {'x': 116, 'y': 1253}, {'x': 117, 'y': 1272}, {'x': 96, 'y': 1272}]}, 'confidence': 0.9918, 'id': 104, 'text': '3.'}, {'boundingBox': {'vertices': [{'x': 119, 'y': 1253}, {'x': 158, 'y': 1255}, {'x': 157, 'y': 1274}, {'x': 119, 'y': 1273}]}, 'confidence': 0.9981, 'id': 105, 'text': 'Any'}, {'boundingBox': {'vertices': [{'x': 160, 'y': 1255}, {'x': 248, 'y': 1253}, {'x': 248, 'y': 1272}, {'x': 160, 'y': 1273}]}, 'confidence': 0.9976, 'id': 106, 'text': 'purchase'}, {'boundingBox': {'vertices': [{'x': 250, 'y': 1254}, {'x': 303, 'y': 1254}, {'x': 303, 'y': 1272}, {'x': 250, 'y': 1272}]}, 'confidence': 0.9971, 'id': 107, 'text': 'order'}, {'boundingBox': {'vertices': [{'x': 305, 'y': 1254}, {'x': 387, 'y': 1253}, {'x': 387, 'y': 1272}, {'x': 305, 'y': 1273}]}, 'confidence': 0.9961, 'id': 108, 'text': 'received'}, {'boundingBox': {'vertices': [{'x': 389, 'y': 1254}, {'x': 415, 'y': 1254}, {'x': 415, 'y': 1274}, {'x': 390, 'y': 1274}]}, 'confidence': 0.999, 'id': 109, 'text': 'by'}, {'boundingBox': {'vertices': [{'x': 417, 'y': 1253}, {'x': 450, 'y': 1253}, {'x': 450, 'y': 1272}, {'x': 417, 'y': 1272}]}, 'confidence': 0.9994, 'id': 110, 'text': 'the'}, {'boundingBox': {'vertices': [{'x': 453, 'y': 1254}, {'x': 505, 'y': 1253}, {'x': 506, 'y': 1272}, {'x': 453, 'y': 1272}]}, 'confidence': 0.9963, 'id': 111, 'text': 'seller'}, {'boundingBox': {'vertices': [{'x': 508, 'y': 1253}, {'x': 542, 'y': 1253}, {'x': 542, 'y': 1272}, {'x': 508, 'y': 1272}]}, 'confidence': 0.9974, 'id': 112, 'text': 'will'}, {'boundingBox': {'vertices': [{'x': 544, 'y': 1253}, {'x': 569, 'y': 1253}, {'x': 569, 'y': 1272}, {'x': 544, 'y': 1272}]}, 'confidence': 0.9992, 'id': 113, 'text': 'be'}, {'boundingBox': {'vertices': [{'x': 571, 'y': 1253}, {'x': 677, 'y': 1253}, {'x': 677, 'y': 1273}, {'x': 571, 'y': 1273}]}, 'confidence': 0.9954, 'id': 114, 'text': 'interpreted'}, {'boundingBox': {'vertices': [{'x': 680, 'y': 1256}, {'x': 704, 'y': 1256}, {'x': 704, 'y': 1272}, {'x': 680, 'y': 1272}]}, 'confidence': 0.9986, 'id': 115, 'text': 'as'}, {'boundingBox': {'vertices': [{'x': 707, 'y': 1253}, {'x': 800, 'y': 1253}, {'x': 800, 'y': 1274}, {'x': 707, 'y': 1274}]}, 'confidence': 0.9986, 'id': 116, 'text': 'accepting'}, {'boundingBox': {'vertices': [{'x': 803, 'y': 1253}, {'x': 840, 'y': 1253}, {'x': 840, 'y': 1272}, {'x': 803, 'y': 1272}]}, 'confidence': 0.9985, 'id': 117, 'text': 'this'}, {'boundingBox': {'vertices': [{'x': 843, 'y': 1253}, {'x': 890, 'y': 1253}, {'x': 890, 'y': 1272}, {'x': 843, 'y': 1272}]}, 'confidence': 0.9968, 'id': 118, 'text': 'offer'}, {'boundingBox': {'vertices': [{'x': 892, 'y': 1253}, {'x': 929, 'y': 1253}, {'x': 929, 'y': 1271}, {'x': 892, 'y': 1272}]}, 'confidence': 0.9869, 'id': 119, 'text': 'and'}, {'boundingBox': {'vertices': [{'x': 932, 'y': 1253}, {'x': 965, 'y': 1254}, {'x': 964, 'y': 1272}, {'x': 931, 'y': 1271}]}, 'confidence': 0.9991, 'id': 120, 'text': 'the'}, {'boundingBox': {'vertices': [{'x': 967, 'y': 1253}, {'x': 1007, 'y': 1253}, {'x': 1007, 'y': 1272}, {'x': 967, 'y': 1272}]}, 'confidence': 0.9966, 'id': 121, 'text': 'sale'}, {'boundingBox': {'vertices': [{'x': 1010, 'y': 1253}, {'x': 1057, 'y': 1253}, {'x': 1057, 'y': 1272}, {'x': 1010, 'y': 1272}]}, 'confidence': 0.9968, 'id': 122, 'text': 'offer'}, {'boundingBox': {'vertices': [{'x': 1058, 'y': 1252}, {'x': 1079, 'y': 1252}, {'x': 1079, 'y': 1272}, {'x': 1058, 'y': 1272}]}, 'confidence': 0.999, 'id': 123, 'text': 'in'}, {'boundingBox': {'vertices': [{'x': 1081, 'y': 1253}, {'x': 1153, 'y': 1253}, {'x': 1153, 'y': 1274}, {'x': 1081, 'y': 1274}]}, 'confidence': 0.9646, 'id': 124, 'text': 'writing.'}, {'boundingBox': {'vertices': [{'x': 1156, 'y': 1252}, {'x': 1193, 'y': 1252}, {'x': 1193, 'y': 1272}, {'x': 1156, 'y': 1272}]}, 'confidence': 0.9994, 'id': 125, 'text': 'The'}, {'boundingBox': {'vertices': [{'x': 1196, 'y': 1253}, {'x': 1251, 'y': 1253}, {'x': 1251, 'y': 1274}, {'x': 1196, 'y': 1274}]}, 'confidence': 0.9963, 'id': 126, 'text': 'buyer'}, {'boundingBox': {'vertices': [{'x': 1254, 'y': 1256}, {'x': 1295, 'y': 1256}, {'x': 1295, 'y': 1274}, {'x': 1254, 'y': 1274}]}, 'confidence': 0.9984, 'id': 127, 'text': 'may'}, {'boundingBox': {'vertices': [{'x': 96, 'y': 1283}, {'x': 184, 'y': 1281}, {'x': 184, 'y': 1301}, {'x': 96, 'y': 1303}]}, 'confidence': 0.9979, 'id': 128, 'text': 'purchase'}, {'boundingBox': {'vertices': [{'x': 187, 'y': 1283}, {'x': 220, 'y': 1283}, {'x': 220, 'y': 1300}, {'x': 187, 'y': 1300}]}, 'confidence': 0.9997, 'id': 129, 'text': 'the'}, {'boundingBox': {'vertices': [{'x': 222, 'y': 1283}, {'x': 298, 'y': 1281}, {'x': 298, 'y': 1301}, {'x': 223, 'y': 1303}]}, 'confidence': 0.9982, 'id': 130, 'text': 'product'}, {'boundingBox': {'vertices': [{'x': 299, 'y': 1282}, {'x': 319, 'y': 1281}, {'x': 319, 'y': 1301}, {'x': 299, 'y': 1301}]}, 'confidence': 0.9994, 'id': 131, 'text': 'in'}, {'boundingBox': {'vertices': [{'x': 321, 'y': 1282}, {'x': 359, 'y': 1281}, {'x': 359, 'y': 1300}, {'x': 322, 'y': 1301}]}, 'confidence': 0.9988, 'id': 132, 'text': 'this'}, {'boundingBox': {'vertices': [{'x': 361, 'y': 1282}, {'x': 408, 'y': 1282}, {'x': 408, 'y': 1301}, {'x': 361, 'y': 1301}]}, 'confidence': 0.9982, 'id': 133, 'text': 'offer'}, {'boundingBox': {'vertices': [{'x': 411, 'y': 1282}, {'x': 453, 'y': 1283}, {'x': 452, 'y': 1303}, {'x': 411, 'y': 1302}]}, 'confidence': 0.9954, 'id': 134, 'text': 'only'}, {'boundingBox': {'vertices': [{'x': 455, 'y': 1283}, {'x': 512, 'y': 1282}, {'x': 512, 'y': 1300}, {'x': 455, 'y': 1301}]}, 'confidence': 0.9988, 'id': 135, 'text': 'under'}, {'boundingBox': {'vertices': [{'x': 514, 'y': 1282}, {'x': 547, 'y': 1282}, {'x': 547, 'y': 1301}, {'x': 514, 'y': 1301}]}, 'confidence': 0.9995, 'id': 136, 'text': 'the'}, {'boundingBox': {'vertices': [{'x': 550, 'y': 1281}, {'x': 609, 'y': 1282}, {'x': 609, 'y': 1301}, {'x': 550, 'y': 1300}]}, 'confidence': 0.9961, 'id': 137, 'text': 'Terms'}, {'boundingBox': {'vertices': [{'x': 611, 'y': 1282}, {'x': 648, 'y': 1282}, {'x': 648, 'y': 1301}, {'x': 611, 'y': 1301}]}, 'confidence': 0.9941, 'id': 138, 'text': 'and'}, {'boundingBox': {'vertices': [{'x': 651, 'y': 1281}, {'x': 752, 'y': 1281}, {'x': 752, 'y': 1300}, {'x': 651, 'y': 1300}]}, 'confidence': 0.9823, 'id': 139, 'text': 'Conditions'}, {'boundingBox': {'vertices': [{'x': 755, 'y': 1282}, {'x': 777, 'y': 1282}, {'x': 777, 'y': 1300}, {'x': 755, 'y': 1301}]}, 'confidence': 0.9961, 'id': 140, 'text': 'of'}, {'boundingBox': {'vertices': [{'x': 779, 'y': 1282}, {'x': 811, 'y': 1282}, {'x': 811, 'y': 1301}, {'x': 779, 'y': 1301}]}, 'confidence': 0.9997, 'id': 141, 'text': 'the'}, {'boundingBox': {'vertices': [{'x': 815, 'y': 1282}, {'x': 871, 'y': 1282}, {'x': 871, 'y': 1301}, {'x': 815, 'y': 1301}]}, 'confidence': 0.9958, 'id': 142, 'text': 'Seller'}, {'boundingBox': {'vertices': [{'x': 872, 'y': 1281}, {'x': 954, 'y': 1281}, {'x': 954, 'y': 1300}, {'x': 872, 'y': 1301}]}, 'confidence': 0.9978, 'id': 143, 'text': 'included'}, {'boundingBox': {'vertices': [{'x': 956, 'y': 1282}, {'x': 976, 'y': 1281}, {'x': 977, 'y': 1301}, {'x': 956, 'y': 1301}]}, 'confidence': 0.9988, 'id': 144, 'text': 'in'}, {'boundingBox': {'vertices': [{'x': 978, 'y': 1282}, {'x': 1016, 'y': 1282}, {'x': 1016, 'y': 1301}, {'x': 978, 'y': 1301}]}, 'confidence': 0.9854, 'id': 145, 'text': 'this'}, {'boundingBox': {'vertices': [{'x': 1018, 'y': 1282}, {'x': 1069, 'y': 1282}, {'x': 1069, 'y': 1301}, {'x': 1018, 'y': 1301}]}, 'confidence': 0.9913, 'id': 146, 'text': 'offer.'}]}], 'stored': True, 'text': \"INVOICE # INV-AJ355548 \\nInvoice ID \\nInvoice Date 9/7/1992 \\nService Details Form \\nCompany Name \\nUpstage Sung Kim \\nName -00 'ess \\nLucy Park Gwanggyojungang-ro 338, Gyeonggi-do, \\nSanghyeon-dong, Suji-gu \\nYongin-si, South Korea \\nAddress \\n7 Pepper Wood Street, 130 Stone Corner \\nTerrace \\nWilkes Barre, Pennsylvania, 18768 \\nUnited States \\nEmail \\nIkitchenman0@arizona.edu \\nAdditional Request Vivamus vestibulum sagittis sapien. Cum sociis natoque \\npenatibus et magnis dis parturient montes, nascetur ridiculus \\nmus. \\nTERMS AND CONDITIONS \\n1. The Seller shall not be liable to the Buyer directly or indirectly for any loss or damage suffered by the Buyer. \\n2. The Seller warrants the product for one (1) year from the date of shipment. \\n3. Any purchase order received by the seller will be interpreted as accepting this offer and the sale offer in writing. The buyer may \\npurchase the product in this offer only under the Terms and Conditions of the Seller included in this offer.\"}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    " \n",
    "api_key = os.environ.get(\"UPSTAGE_API_KEY\")\n",
    "filename = \"data/invoice.png\"\n",
    " \n",
    "url = \"https://api.upstage.ai/v1/document-ai/ocr\"\n",
    "headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "files = {\"document\": open(filename, \"rb\")}\n",
    "response = requests.post(url, headers=headers, files=files)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea41da30-d573-4dd8-bfc4-8be1de7d5d14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
